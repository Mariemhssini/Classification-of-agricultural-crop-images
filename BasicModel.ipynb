{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a28a10b-4e62-4b9c-bc1b-57b524db02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, MaxPool2D\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a856fc1-6b6e-4e28-8815-ff4b7743f7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>crop</th>\n",
       "      <th>croplabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/kag2/sugarcane/sugarcane037ahs.jpeg</td>\n",
       "      <td>sugarcane</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/input/kag2/sugarcane/sugarcane034a.jpeg</td>\n",
       "      <td>sugarcane</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/kaggle/input/kag2/sugarcane/sugarcane032arot....</td>\n",
       "      <td>sugarcane</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/kaggle/input/kag2/sugarcane/sugarcane036ahs.jpeg</td>\n",
       "      <td>sugarcane</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/kaggle/input/kag2/sugarcane/sugarcane023ahs.jpeg</td>\n",
       "      <td>sugarcane</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               path       crop  \\\n",
       "0           0  /kaggle/input/kag2/sugarcane/sugarcane037ahs.jpeg  sugarcane   \n",
       "1           1    /kaggle/input/kag2/sugarcane/sugarcane034a.jpeg  sugarcane   \n",
       "2           2  /kaggle/input/kag2/sugarcane/sugarcane032arot....  sugarcane   \n",
       "3           3  /kaggle/input/kag2/sugarcane/sugarcane036ahs.jpeg  sugarcane   \n",
       "4           4  /kaggle/input/kag2/sugarcane/sugarcane023ahs.jpeg  sugarcane   \n",
       "\n",
       "   croplabel  \n",
       "0          3  \n",
       "1          3  \n",
       "2          3  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemin vers le répertoire principal des données\n",
    "data_dir = 'C:/Users/mariem hssn/OneDrive/Bureau/AIProject/archive (1)/'\n",
    "\n",
    "# Nom du fichier CSV\n",
    "file_name = 'Crop_details.csv'\n",
    "\n",
    "# Chemin complet du fichier CSV\n",
    "file_path = data_dir + file_name\n",
    "\n",
    "# Charger le fichier CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "857e80f9-5e7c-4e9c-acdf-ec89b7602507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jute', 'maize', 'rice', 'sugarcane', 'wheat']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = os.listdir(\"C:/Users/mariem hssn/OneDrive/Bureau/AIProject/archive (1)/kag2\")\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b38261a-adc0-4d39-b818-39e6e8f0005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "getData = ImageDataGenerator(rescale=1/255,\n",
    "                             shear_range=0.3,\n",
    "                             horizontal_flip=True,\n",
    "                            vertical_flip= True,\n",
    "                            rotation_range=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af90e56f-0068-45e9-89c1-d76a65a29d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 804 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "kag2_data = getData.flow_from_directory(\"C:/Users/mariem hssn/OneDrive/Bureau/AIProject/archive (1)/kag2\",\n",
    "                                       target_size=(224,224),\n",
    "                                       class_mode='categorical',\n",
    "                                       shuffle = True,\n",
    "                                       batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11d194cb-1009-46f8-b5c7-fd9cc66e7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3eea845b-2131-4a9e-a1e4-6e4e549ff681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "beccdcde-763c-4622-aabd-18c46fa4fdf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3506\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   3476\u001b[0m \n\u001b[0;32m   3477\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m   3504\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 3506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3510\u001b[0m     )\n\u001b[0;32m   3511\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[0;32m   3512\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3513\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3518\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[0;32m   3519\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfda4c-15c7-40de-a04e-774e01e5a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 804\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "\n",
    "final_model = model.fit(kag2_data,\n",
    "                        steps_per_epoch=num_train_samples//batch_size,\n",
    "                        epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e27bf-4f24-4fcf-8fa3-abdcbf6688e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "crop_data = test_datagen.flow_from_directory(\"../input/agriculture-crop-images/crop_images\",\n",
    "                                       target_size=(224,224),\n",
    "                                       class_mode='categorical',\n",
    "                                       shuffle = True,\n",
    "                                       batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0990790-46b5-439d-9aa8-4815dbd1219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(final_model.history['loss'],label='train_loss')\n",
    "plt.plot(final_model.history['accuracy'],label='train_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e68cbe-6c00-40ff-b095-4f8a52bea889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = crop_data.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "Y_pred = model.predict_generator(crop_data)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098cb1d-6ee9-45a6-8986-a47f8b2a3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_crop(path,actual,class_labels):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img,(224,224))\n",
    "    img = np.array(img).reshape((1,224,224,3))\n",
    "    Y_pred = model.predict(img)\n",
    "    y_pred = np.argmax(Y_pred,axis=1)\n",
    "    if y_pred == actual:\n",
    "        print(\"Correct Prediction 🎉🎊🎉\")\n",
    "    else:\n",
    "        print(\"Wrong Prediction 💥💥💥\")\n",
    "    print('Actual class \"{0}\" and predicted class \"{1}\"'.format(class_labels[int(y_pred)],class_labels[actual]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae680da-b96b-4068-9c35-57a22c9fef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_crop('/kaggle/input/agriculture-crop-images/kag2/rice/rice024ahs.jpeg',2,class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef38ce-0393-46a2-8051-26f07aa2f71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
